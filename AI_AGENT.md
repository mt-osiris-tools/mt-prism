# AI_AGENT.md

This file provides guidance to AI coding assistants (Claude Code, Cursor, Aider, etc.) when working with the MT-PRISM codebase.

## Project Overview

**MT-PRISM** is a **local-first AI plugin** that automates the software discovery process from Product Requirements Document (PRD) to Technical Design Document (TDD).

**Supported AI Providers**: Anthropic Claude, OpenAI GPT-4, Google Gemini
**Supported Platforms**: Claude Code, Claude Code CLI, Cursor, GitHub Copilot CLI, OpenAI Codex, Codex CLI, VS Code (OpenCode)

## Architecture Principles

### Local-First Design

MT-PRISM is designed to run **entirely on the developer's machine** with **zero infrastructure**:

- **No servers** - Runs within AI coding assistant environment
- **No databases** - Uses local `.prism/` directory for storage
- **No Docker/Kubernetes** - Simple Node.js application
- **No cloud services** - All data stored locally
- **Offline capable** - Works offline except for AI API and MCP calls

### Plugin Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI Coding Assistant               â”‚
â”‚   (Claude Code, Cursor, Aider, etc.)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       MT-PRISM Plugin               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Skills (Modules)           â”‚    â”‚
â”‚  â”‚  â€¢ prism.analyze-prd        â”‚    â”‚
â”‚  â”‚  â€¢ prism.analyze-figma      â”‚    â”‚
â”‚  â”‚  â€¢ prism.validate           â”‚    â”‚
â”‚  â”‚  â€¢ prism.clarify            â”‚    â”‚
â”‚  â”‚  â€¢ prism.generate-tdd       â”‚    â”‚
â”‚  â”‚  â€¢ prism.discover (full)    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  LLM Abstraction Layer      â”‚    â”‚
â”‚  â”‚  â€¢ Anthropic (Claude)       â”‚    â”‚
â”‚  â”‚  â€¢ OpenAI (GPT-4)           â”‚    â”‚
â”‚  â”‚  â€¢ Google (Gemini)          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    MCPs (Model Context Protocol)    â”‚
â”‚  â€¢ Confluence (Atlassian)           â”‚
â”‚  â€¢ Figma                            â”‚
â”‚  â€¢ Jira (optional)                  â”‚
â”‚  â€¢ Slack (optional)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Skills Overview

MT-PRISM provides 5 core skills that can be used independently or orchestrated together:

### 1. PRD Analyzer (`prism.analyze-prd`)

**Purpose**: Extract structured requirements from PRD documents

**Capabilities**:
- Parse Confluence pages via Atlassian MCP
- Extract from local files (markdown, PDF, DOCX)
- Classify requirements by type and priority
- Detect ambiguities and missing information
- Generate dependency graphs
- Output: `requirements.yaml`

**Target Performance**: < 2 minutes, 95%+ accuracy

### 2. Figma Analyzer (`prism.analyze-figma`)

**Purpose**: Extract UI specifications from Figma designs

**Capabilities**:
- Fetch Figma data via Figma MCP
- Extract components with variants
- Identify design tokens (colors, typography, spacing)
- Recognize UI patterns (forms, modals, tables)
- Output: `components.yaml`

**Target Performance**: < 3 minutes

### 3. Requirements Validator (`prism.validate`)

**Purpose**: Cross-validate requirements against designs

**Capabilities**:
- Map requirements to UI components
- Detect missing UI for requirements
- Identify Figma components without requirements
- Flag inconsistencies and gaps
- Generate clarification questions
- Output: `gaps.yaml`, `questions.yaml`

**Target Performance**: < 3 minutes, 90%+ gap detection

### 4. Clarification Manager (`prism.clarify`)

**Purpose**: Manage Q&A workflow with stakeholders

**Capabilities**:
- Interactive Q&A mode
- Jira integration for async tickets
- Slack integration for async messages
- Update requirements based on responses
- Trigger re-validation
- Output: Updated `requirements.yaml`

### 5. TDD Generator (`prism.generate-tdd`)

**Purpose**: Generate comprehensive Technical Design Document

**Capabilities**:
- Create 30-50 page TDD with all sections
- Generate OpenAPI 3.1 API specifications
- Produce executable SQL database schemas
- Create implementation task breakdown
- Include architecture diagrams (Mermaid)
- Output: `TDD.md`, `api-spec.yaml`, `database-schema.sql`, `tasks.json`

**Target Performance**: < 5 minutes

### 6. Full Workflow (`prism.discover`)

**Purpose**: Orchestrate complete PRD-to-TDD automation

**Workflow**:
1. Analyze PRD â†’ `requirements.yaml`
2. Analyze Figma â†’ `components.yaml`
3. Validate â†’ `gaps.yaml`, `questions.yaml`
4. Clarify (if gaps found) â†’ Updated requirements
5. Generate TDD â†’ Complete documentation

**Target Performance**: < 20 minutes (excluding stakeholder response time)

## Local File Structure

All data is stored locally in the `.prism/` directory:

```
project-root/
â”œâ”€â”€ .prism/
â”‚   â”œâ”€â”€ config.yaml           # User configuration
â”‚   â”œâ”€â”€ session.json          # Current session state
â”‚   â”œâ”€â”€ outputs/
â”‚   â”‚   â”œâ”€â”€ requirements.yaml # PRD analysis output
â”‚   â”‚   â”œâ”€â”€ components.yaml   # Figma analysis output
â”‚   â”‚   â”œâ”€â”€ gaps.yaml         # Validation output
â”‚   â”‚   â”œâ”€â”€ questions.yaml    # Clarification questions
â”‚   â”‚   â”œâ”€â”€ TDD.md            # Generated TDD
â”‚   â”‚   â”œâ”€â”€ api-spec.yaml     # API specification
â”‚   â”‚   â””â”€â”€ database-schema.sql
â”‚   â””â”€â”€ cache/                # Optional caching
â”‚       â””â”€â”€ <hash>.json
â””â”€â”€ .env                      # API keys (gitignored)
```

## LLM Abstraction Layer

All skills use a unified interface for AI provider calls:

```typescript
interface LLMProvider {
  // Generate text completion
  generateText(prompt: string, options?: GenerateOptions): Promise<string>

  // Stream text completion
  streamText(prompt: string, options?: GenerateOptions): AsyncGenerator<string>

  // Generate structured output matching schema
  generateStructured<T>(
    prompt: string,
    schema: ZodSchema<T>,
    options?: GenerateOptions
  ): Promise<T>

  // Get provider info
  getInfo(): ProviderInfo

  // Estimate cost for request
  estimateCost(tokens: number): number
}
```

**Supported Providers**:
- **Anthropic**: Claude Sonnet 4.5, Opus, Haiku (~$4/workflow)
- **OpenAI**: GPT-4, GPT-4 Turbo (~$3.50/workflow)
- **Google**: Gemini Pro, Ultra (~$2.50/workflow)

## Environment Configuration

Create `.env` file in project root:

```bash
# Choose primary AI provider
AI_PROVIDER=anthropic  # Options: anthropic, openai, google

# Provider API keys (configure the one(s) you'll use)
ANTHROPIC_API_KEY=sk-ant-xxxxx     # For Claude
OPENAI_API_KEY=sk-xxxxx            # For GPT-4
GOOGLE_API_KEY=xxxxx               # For Gemini

# Optional: Specific model selection (uses defaults if not set)
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929
OPENAI_MODEL=gpt-4-turbo
GOOGLE_MODEL=gemini-pro

# MCP Configuration (optional, for Confluence/Figma/etc.)
CONFLUENCE_URL=https://your-domain.atlassian.net
CONFLUENCE_TOKEN=<token>
FIGMA_ACCESS_TOKEN=<token>
JIRA_URL=https://your-domain.atlassian.net
SLACK_TOKEN=<token>
```

## Usage Examples

### Example 1: Analyze PRD from Confluence

```bash
# Via Claude Code
/prism.analyze-prd --source https://company.atlassian.net/wiki/pages/123456

# Via Cursor
Cmd+Shift+P â†’ "PRISM: Analyze PRD"

# Via CLI
prism analyze-prd --source https://company.atlassian.net/wiki/pages/123456
```

Output: `.prism/outputs/requirements.yaml`

### Example 2: Full Discovery Workflow

```bash
# Via Claude Code
/prism.discover \
  --prd https://company.atlassian.net/wiki/pages/123456 \
  --figma https://figma.com/file/abc123/ProjectX

# Via Cursor
Cmd+Shift+P â†’ "PRISM: Full Discovery"

# Via CLI
prism discover \
  --prd https://company.atlassian.net/wiki/pages/123456 \
  --figma https://figma.com/file/abc123/ProjectX
```

Output: Complete `.prism/outputs/` directory with all artifacts

### Example 3: Interactive Clarification

```bash
# Start clarification session
/prism.clarify --questions .prism/outputs/questions.yaml --mode interactive

# Questions presented one by one:
# Q1 [CRITICAL]: Should user profile editing support real-time validation?
# Suggestions: (a) Yes, validate on blur (b) Yes, validate on submit (c) No validation
# Your answer: _
```

## Development Guidelines

### When Implementing Skills

1. **Use LLM Abstraction Layer**: Never call provider SDKs directly
   ```typescript
   // âŒ Bad
   import Anthropic from '@anthropic-ai/sdk'
   const client = new Anthropic(...)

   // âœ… Good
   import { createLLMProvider } from '../utils/llm'
   const llm = await createLLMProvider()
   const result = await llm.generateText(prompt)
   ```

2. **Store All Data Locally**: Use `.prism/` directory
   ```typescript
   // âŒ Bad
   await uploadToS3(data)

   // âœ… Good
   await writeYAML('.prism/outputs/requirements.yaml', data)
   ```

3. **Validate Outputs**: Use Zod schemas
   ```typescript
   import { RequirementsOutputSchema } from '../types/requirement'
   const validated = RequirementsOutputSchema.parse(rawOutput)
   ```

4. **Provide Progress Updates**: Keep users informed
   ```typescript
   console.log('ğŸ“„ Analyzing PRD...')
   console.log('ğŸ¤– Calling AI provider...')
   console.log('âœ… Extracted 23 requirements')
   ```

5. **Handle Errors Gracefully**: Provide actionable error messages
   ```typescript
   try {
     await fetchConfluencePage(url)
   } catch (error) {
     if (error.status === 404) {
       throw new Error(
         'PRD not found. Check URL or use local file: prism analyze-prd --source ./local-prd.md'
       )
     }
   }
   ```

### Testing Strategy

```bash
# Unit tests for individual skills
npm run test:unit

# Integration tests with MCP mocks
npm run test:integration

# E2E tests with real APIs (requires test credentials)
npm run test:e2e

# Target: 80%+ code coverage
npm run test:coverage
```

## Project Structure

```
mt-prism/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ skills/           # Skill implementations
â”‚   â”‚   â”œâ”€â”€ prd-analyzer.ts
â”‚   â”‚   â”œâ”€â”€ figma-analyzer.ts
â”‚   â”‚   â”œâ”€â”€ validator.ts
â”‚   â”‚   â”œâ”€â”€ clarification-manager.ts
â”‚   â”‚   â”œâ”€â”€ tdd-generator.ts
â”‚   â”‚   â””â”€â”€ workflow.ts
â”‚   â”œâ”€â”€ providers/        # LLM provider implementations
â”‚   â”‚   â”œâ”€â”€ anthropic.ts
â”‚   â”‚   â”œâ”€â”€ openai.ts
â”‚   â”‚   â”œâ”€â”€ google.ts
â”‚   â”‚   â””â”€â”€ factory.ts
â”‚   â”œâ”€â”€ types/           # TypeScript type definitions
â”‚   â”‚   â”œâ”€â”€ requirement.ts
â”‚   â”‚   â”œâ”€â”€ component.ts
â”‚   â”‚   â”œâ”€â”€ gap.ts
â”‚   â”‚   â””â”€â”€ session.ts
â”‚   â””â”€â”€ utils/           # Shared utilities
â”‚       â”œâ”€â”€ llm.ts       # LLM abstraction
â”‚       â”œâ”€â”€ files.ts     # File operations
â”‚       â”œâ”€â”€ prompts.ts   # Prompt templates
â”‚       â””â”€â”€ validation.ts # Schema validation
â”œâ”€â”€ prompts/             # AI prompts for each skill
â”‚   â”œâ”€â”€ prd-analyzer.md
â”‚   â”œâ”€â”€ figma-analyzer.md
â”‚   â”œâ”€â”€ validator.md
â”‚   â””â”€â”€ tdd-generator.md
â”œâ”€â”€ templates/           # Output schemas and templates
â”‚   â”œâ”€â”€ requirements-schema.yaml
â”‚   â”œâ”€â”€ components-schema.yaml
â”‚   â””â”€â”€ tdd-template.md
â”œâ”€â”€ tests/              # Test suite
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ docs/               # Comprehensive documentation
â”‚   â”œâ”€â”€ LLM_PROVIDER_GUIDE.md
â”‚   â”œâ”€â”€ AGENT_INTEGRATION_GUIDE.md
â”‚   â”œâ”€â”€ MVP_AND_GIT_STRATEGY.md
â”‚   â””â”€â”€ LOCAL_FIRST_STRATEGY.md
â””â”€â”€ examples/           # Example inputs for testing
    â”œâ”€â”€ sample-prd.md
    â””â”€â”€ sample-figma-data.json
```

## Performance Targets

| Operation | Target | Typical | Notes |
|-----------|--------|---------|-------|
| PRD Analysis | < 2 min | 1m 45s | 5-10 page PRD |
| Figma Analysis | < 3 min | 2m 15s | 20-50 screens |
| Validation | < 3 min | 1m 52s | 20 req + 40 comp |
| TDD Generation | < 5 min | 3m 45s | Full spec |
| **Full Workflow** | **< 20 min** | **~17 min** | **End-to-end** |

## Cost Estimates (Per Workflow)

| Provider | Input Tokens | Output Tokens | Cost/Workflow |
|----------|-------------|---------------|---------------|
| Anthropic Claude | ~40K | ~12K | ~$4.00 |
| OpenAI GPT-4 | ~40K | ~12K | ~$3.50 |
| Google Gemini | ~40K | ~12K | ~$2.50 |

**Annual Cost** (100 workflows/month): $3,000-$4,800 depending on provider

## Git Workflow

Follow the branching strategy defined in `docs/MVP_AND_GIT_STRATEGY.md`:

- `main` - Production releases only
- `develop` - Integration branch
- `feature/*` - Feature development
- `release/*` - Release preparation
- `hotfix/*` - Critical fixes

Use conventional commits:
```bash
feat: add PRD analyzer skill
fix: handle empty Figma components
docs: update README with multi-provider info
test: add validation tests
```

## Key Documentation

| Document | Purpose |
|----------|---------|
| [README.md](README.md) | Project overview and quick start |
| [QUICKSTART.md](QUICKSTART.md) | 1-hour implementation guide |
| [LLM_PROVIDER_GUIDE.md](docs/LLM_PROVIDER_GUIDE.md) | Multi-provider configuration |
| [AGENT_INTEGRATION_GUIDE.md](docs/AGENT_INTEGRATION_GUIDE.md) | Platform-specific setup |
| [LOCAL_FIRST_STRATEGY.md](docs/LOCAL_FIRST_STRATEGY.md) | Zero-infrastructure approach |
| [MVP_AND_GIT_STRATEGY.md](docs/MVP_AND_GIT_STRATEGY.md) | Development roadmap |

## Success Criteria

- âœ… **95%+ accuracy** in requirement extraction
- âœ… **90%+ gap detection** rate
- âœ… **< 20 minutes** full workflow time
- âœ… **4.5/5** TDD quality rating
- âœ… **Zero infrastructure** costs
- âœ… **$60K total** Year 1 cost (vs $1.3M for full system)

## Active Technologies

**Core Stack**:
- TypeScript 5.3+ for type safety
- Node.js 20 LTS for runtime
- Zod for schema validation
- YAML for data serialization

**AI Provider SDKs**:
- @anthropic-ai/sdk ^0.27.0 (Claude)
- openai ^4.0.0 (GPT-4)
- @google/generative-ai ^0.1.0 (Gemini)

**MCPs**:
- Atlassian MCP (Confluence, Jira)
- Figma MCP
- Slack MCP (optional)

**Development**:
- Vitest for testing
- ESLint + Prettier for code quality

## Recent Changes

**2025-11-19**: Multi-provider support added
- LLM abstraction layer implemented
- Support for Claude, GPT-4, and Gemini
- Provider configuration guide created

**2025-11-19**: Multi-platform support added
- Integration guides for 7 platforms
- Platform-agnostic design
- Comprehensive setup instructions

**2025-11-19**: Local-first strategy documented
- Zero infrastructure approach
- `.prism/` directory structure
- Offline-capable design

---

**For AI Assistants**: This project prioritizes **simplicity**, **local-first design**, and **developer experience**. Always prefer local storage over cloud, simple solutions over complex architectures, and clear documentation over clever code.
